# -*- coding: utf-8 -*-
"""Insurance_Premium_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LcRFI7abu5KKiBgcqLGNhK5YWXj4rxvm
"""

import pandas as pd
import numpy as np

data = pd.read_csv("/content/insurance.csv")
data.head(5)

data.info()

data.isnull().sum()

data.describe().T

data.describe(include='object').T

data.duplicated().sum()

data.drop_duplicates(inplace=True)

"""Observations:

This dataset contains 1338 rows and 7 columns.

There are no null values in this dataset.

There are 4 numeric as well as 3 categorical features present in this dataset.

There was 1 duplicate row present in this dataset.
"""

pip install pandas-profiling

# Commented out IPython magic to ensure Python compatibility.
import seaborn as sns
import plotly.express as px
import matplotlib.pyplot as plt
from pandas_profiling import ProfileReport
import matplotlib
# %matplotlib inline

plt.figure(figsize=(35,35))
sns.pairplot(data=data, hue='sex', corner = True)

# Retrieving numerical columns from dataset
numeric_columns = [feature for feature in data.columns if data[feature].dtype != 'O']
# Retrieving categorical columns from dataset
categorical_columns = [feature for feature in data.columns if data[feature].dtype == 'O']

print(f"This data set contains {len(numeric_columns)} numerical columns: {numeric_columns}")
print(f"This data set contains {len(categorical_columns)} categorical columns: {categorical_columns}")

data.skew()

import matplotlib.pyplot as plt
import seaborn as sns

fig, axes = plt.subplots(2, 2, figsize=(15, 15), dpi=500)

fig.suptitle('Univariate Analysis', fontsize=20, fontweight='bold', alpha=0.8, y=1.)

for i, column in enumerate(numeric_columns):

    ax = axes[i // 2, i % 2]

    sns.distplot(x=data[column], kde=True, ax=ax)

    ax.axvline(data[column].mean(), linestyle="dashed", label="mean", color="k")

    ax.set_xlabel(column)

    ax.legend(loc="best")

    ax.set_title(f"Distribution of {column}", color="navy")

plt.tight_layout()

plt.show()

import scipy.stats as stats

def diagnostic_plots(df, variable):
    '''
    Generate diagnostic plots for a specific variable.

    Parameters:
        df (DataFrame): The input DataFrame containing the data.
        variable (str): The name of the variable to analyze.

    Returns:
        None: The function displays the histogram and Q-Q plot side by side.

    '''

    # Create a figure with two subplots (1 row, 2 columns)
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))

    # Plot the histogram on the first subplot
    axes[0].hist(df[variable], bins=20, edgecolor='black', color='skyblue')
    axes[0].set_xlabel(variable)
    axes[0].set_title('Histogram')

    # Plot the Q-Q plot on the second subplot
    stats.probplot(df[variable], dist="norm", plot=axes[1])
    axes[1].set_ylabel(variable)
    axes[1].set_title('Q-Q Plot')

    # Display the plots
    plt.show()

for col in numeric_columns:
    diagnostic_plots(data, col)

def age_group(X):

  if X in range(18,20):
    return '18-20'
  elif X in range(20,30):
    return '20-30'
  elif X in range(30,40):
    return '30-40'
  elif X in range(40,50):
    return '40-50'
  elif X in range(50,60):
    return '50-60'
  else:
    return '60+'

data['age_group']=data['age'].apply(age_group)

import seaborn as sns
import matplotlib.pyplot as plt

def plot_age_distribution(data):
    """
    Plot the age distribution of current health insurers.

    Parameters:
        data (DataFrame): The input DataFrame containing age information.

    Returns:
        None: The function displays the age distribution plot.
    """
    sns.set(style="whitegrid")
    plt.figure(figsize=(20, 8))

    # Calculate the total count for percentage calculation
    total = float(len(data))

    # Create a countplot for age groups
    ax = sns.countplot(x="age_group", data=data)

    # Add title and adjust plot aesthetics
    plt.title('Age of Current Health Insurers', fontsize=20)
    plt.xlabel('Age Group')
    plt.ylabel('Count')

    # Annotate each bar with the percentage of occurrences
    for p in ax.patches:
        percentage = '{:.1f}%'.format(100 * p.get_height() / total)
        x = p.get_x() + p.get_width() / 2
        y = p.get_height()
        ax.annotate(percentage, (x, y), ha='center', va='bottom', fontsize=12)

    # Display the plot
    plt.show()

# Plot the age distribution
plot_age_distribution(data)

data.drop(["age_group"], axis=1, inplace=True)

scatter_fig = px.scatter(data, x="age", y="expenses", color="region", symbol="sex",
                         hover_data=['bmi', 'smoker', 'children'])

# Set the title of the plot
scatter_fig.update_layout(title_text='Relationship between Age and Expenses', title_font_size=20)

# Show the scatter plot
scatter_fig.show()

# Create a scatter plot with a linear regression model fit line
sns.lmplot(data=data, x='age', y='expenses', hue="smoker", height=7)

# Set the title for the plot
plt.title('Relationship between Age and Expenses (with Smoker distinction)', fontsize=16)

# Show the plot
plt.show()

# Set the width and height of the figure
plt.figure(figsize=(10, 5))

# Calculate the correlation matrix
corr = data.corr()

# Create a heatmap to visualize the correlation matrix with annotations
ax = sns.heatmap(corr, annot=True)

# Set the title for the plot
plt.title('Correlation Heatmap', fontsize=16)

# Show the plot
plt.show()

# One hot encoding on categorical columns
data = pd.get_dummies(data,columns = ['sex', 'smoker', 'region'],drop_first = True)

data.head(5)

data.sample(10)

X=data.drop(columns=['expenses'], axis=1)
y=data['expenses']

X

y

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train.shape,X_test.shape,X.shape

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X_train

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
model = LinearRegression()
model.fit(X_train , y_train)
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
print(f"Mean Squared Error (MSE): {mse}")
print(y_pred[:5])
print(y_test[:5])

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.metrics import mean_squared_error, r2_score
alpha = 1.0  # You can adjust the alpha (regularization strength) as needed
ridge_model = Ridge(alpha=alpha)
ridge_model.fit(X_train, y_train)
y_pred = ridge_model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse}")
print(f"R-squared (R2) Score: {r2}")
print(y_pred[:5])
print(y_test[:5])

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Lasso
from sklearn.metrics import mean_squared_error, r2_score
# Create a Lasso Regression model
lasso = Lasso(alpha=1.0)
# Fit the model to the training data
lasso.fit(X_train, y_train)
# Make predictions on the test data
y_pred = lasso.predict(X_test)
# Calculate Mean Squared Error (MSE) and R-squared (R2) to evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f'Mean Squared Error (MSE): {mse}')
print(f'R-squared (R2): {r2}')
print(y_pred[:5])
print(y_test[:5])

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error, r2_score
svr = SVR(kernel='linear', C=1.0)
svr.fit(X_train, y_train)
y_pred = svr.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R-squared (R2) Score:", r2)
print(y_pred[:5])
print(y_test[:5])

from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

regressor = DecisionTreeRegressor(random_state=42)

regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse}")
print(f"R-squared (Accuracy): {r2}")
print(y_pred[:5])
print(y_test[:5])

from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import r2_score

regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)
r2 = r2_score(y_test, y_pred)
print(f"R-squared score: {r2}")
print(y_pred[:5])
print(y_test[:5])

import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score

regressor = xgb.XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=3)
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)

r_squared = r2_score(y_test, y_pred)
print(f"R-squared (RÂ²) Score: {r_squared}")
print(y_pred[:5])
print(y_test[:5])

# the regression models
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge,Lasso
from sklearn.neighbors import KNeighborsRegressor
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import BaggingRegressor
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
from sklearn.cluster import KMeans

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
from sklearn.metrics import silhouette_score

# feature-selection methods
from sklearn.feature_selection import SelectFromModel

    mse = mean_squared_error(true, predicted)  # Calculate Mean Squared Error
    mae = mean_absolute_error(true, predicted)  # Calculate Mean Absolute Error
    rmse = np.sqrt(mse)  # Calculate Root Mean Squared Error
    r2 = r2_score(true, predicted)  # Calculate R2 Score
    adj_r2 = 1 - (1 - r2) * (len(true) - 1) / (len(true) - X_test.shape[1] - 1)  # Calculate Adjusted R2 Score

    return mse, mae, rmse, r2, adj_r2

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import pandas as pd

def evaluate_models(X, y, models):

    train_metrics = []
    test_metrics = []

    # Separate dataset into train and test sets
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Scaling the dataset
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)

    for model_name, model in models.items():
        model.fit(X_train, y_train)  # Train the model

        # Make predictions on training and test sets
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)

        # Evaluate model performance for training set
        train_metrics.append(evaluate_model_metrics(model_name, y_train, y_train_pred, X_train))

        # Evaluate model performance for test set
        test_metrics.append(evaluate_model_metrics(model_name, y_test, y_test_pred, X_test))

    # Create DataFrames for training and test set metrics
    train_report = pd.DataFrame(train_metrics, columns=['Model', 'Train Mean Squared Error',
                                                        'Train Mean Absolute Error',
                                                        'Train Root Mean Squared Error',
                                                        'Train R Squared', 'Train Adjusted R2 Score'])

    test_report = pd.DataFrame(test_metrics, columns=['Model', 'Test Mean Squared Error',
                                                      'Test Mean Absolute Error',
                                                      'Test Root Mean Squared Error',
                                                      'Test R Squared', 'Test Adjusted R2 Score'])

    return train_report, test_report


def evaluate_model_metrics(model_name, true, predicted, X):

    mse = mean_squared_error(true, predicted)
    mae = mean_absolute_error(true, predicted)
    rmse = np.sqrt(mse)
    r2_score_value = r2_score(true, predicted)
    adj_r2_score = 1 - (1 - r2_score_value) * (len(true) - 1) / (len(true) - X.shape[1] - 1)
    return model_name, mse, mae, rmse, r2_score_value, adj_r2_score

# Dictionary which contains models for the experiment
models = {
    "Linear Regression": LinearRegression(),
    "Ridge Regression": Ridge(random_state=1),
    "Lasso Regression": Lasso(random_state=1),
    "Support Vector Regression": SVR(kernel='linear'),
    "Decision Tree Regressor": DecisionTreeRegressor(random_state=1),
    "Bagging Regressor": BaggingRegressor(random_state=1),
    "AdaBoost Regressor": AdaBoostRegressor(random_state=1),
    "Gradient Boosting Regressor": GradientBoostingRegressor(random_state=1),
    "XGB Regressor": XGBRegressor()
}

train_report_df, test_report_df = evaluate_models(X,y, models)

train_report_df

test_report_df

import matplotlib.pyplot as plt

# Set the figure size
plt.figure(figsize=(20, 15))

# Plot Mean Squared Error comparison
plt.subplot(2, 3, 1)
plt.plot(test_report_df['Model'], test_report_df['Test Mean Squared Error'], marker='o', color='r', label='Test Mean Squared Error')
plt.plot(train_report_df['Model'], train_report_df['Train Mean Squared Error'], marker='o', color='g', label='Train Mean Squared Error')
plt.xlabel("Model", fontsize=12)
plt.ylabel("Mean Squared Error", fontsize=12)
plt.title("Mean Squared Error for Training and Test Data", fontsize=15)
plt.xticks(rotation=90)  # Rotating the x labels
plt.legend()
plt.tight_layout()

# Plot Mean Absolute Error Comparison
plt.subplot(2, 3, 2)
plt.plot(test_report_df['Model'], test_report_df['Test Mean Absolute Error'], marker='o', color='r', label='Test Mean Absolute Error')
plt.plot(train_report_df['Model'], train_report_df['Train Mean Absolute Error'], marker='o', color='g', label='Train Mean Absolute Error')
plt.xlabel("Model", fontsize=12)
plt.ylabel("Mean Absolute Error", fontsize=12)
plt.title("Mean Absolute Error for Training and Test Data", fontsize=15)
plt.xticks(rotation=90)  # Rotating the x labels
plt.legend()
plt.tight_layout()

# Plot Root Mean Squared Error Comparison
plt.subplot(2, 3, 3)
plt.plot(test_report_df['Model'], test_report_df['Test Root Mean Squared Error'], marker='o', color='r', label='Test Root Mean Squared Error')
plt.plot(train_report_df['Model'], train_report_df['Train Root Mean Squared Error'], marker='o', color='g', label='Train Root Mean Squared Error')
plt.xlabel("Model", fontsize=12)
plt.ylabel("Root Mean Squared Error", fontsize=12)
plt.title("Root Mean Squared Error for Training and Test Data", fontsize=15)
plt.xticks(rotation=90)  # Rotating the x labels
plt.legend()
plt.tight_layout()

# Plot R2 Score Comparison
plt.subplot(2, 3, 4)
plt.plot(test_report_df['Model'], test_report_df['Test R Squared'], marker='o', color='r', label='Test R Squared')
plt.plot(train_report_df['Model'], train_report_df['Train R Squared'], marker='o', color='g', label='Train R Squared')
plt.xlabel("Model", fontsize=12)
plt.ylabel("R2 Score", fontsize=12)
plt.title("R2 Score for Training and Test Data", fontsize=15)
plt.xticks(rotation=90)  # Rotating the x labels
plt.legend()
plt.tight_layout()

# Plot Adjusted R2 Score Comparison
plt.subplot(2, 3, 5)
plt.plot(test_report_df['Model'], test_report_df['Test Adjusted R2 Score'], marker='o', color='r', label='Test Adjusted R2 Score')
plt.plot(train_report_df['Model'], train_report_df['Train Adjusted R2 Score'], marker='o', color='g', label='Train Adjusted R2 Score')
plt.xlabel("Model", fontsize=12)
plt.ylabel("Adjusted R2 Score", fontsize=12)
plt.title("Adjusted R2 Score for Training and Test Data", fontsize=15)
plt.xticks(rotation=90)  # Rotating the x labels
plt.legend()
plt.tight_layout()

# Show the plots
plt.show()